---
layout: default
title: Random Variables
nav_order: 4
parent: Probability & Statistics
---


## Variables Aleatorias

Las variables aleatorias son un concepto central en la teor√≠a de la probabilidad y estad√≠stica, representando cantidades que resultan de un experimento aleatorio y cuyos valores no son predecibles con certeza antes de realizar el experimento. Estas variables pueden clasificarse en dos grandes categor√≠as: variables aleatorias discretas y variables aleatorias continuas.

{: .highlight}
Una variable aleatoria puede ser entendida como una funci√≥n que asigna un valor num√©rico a cada resultado de un espacio muestral asociado con un experimento aleatorio. Por ejemplo, si lanzas un dado, el resultado (n√∫mero de puntos hacia arriba) es el valor que toma la variable aleatoria.

## Variables aleatorias discretas

{: .note}
Las **variables aleatorias discretas** son aquellas que toman un n√∫mero finito o contablemente infinito de valores distintos. Cada uno de estos valores tiene una probabilidad asociada, y la suma de todas estas probabilidades debe ser igual a uno. Este tipo de variable es muy com√∫n en la estad√≠stica y la teor√≠a de la probabilidad, y se utiliza frecuentemente para modelar situaciones donde los resultados son claramente separables y contables. Pueden adoptar valores que se pueden contar, como 0, 1, 2, ..., n, o una lista de valores espec√≠ficos como {-3, -1, 0, 1, 5}.

### Variable Aleatoria de Bernoulli

{: .highlight}
Una variable aleatoria de Bernoulli **es un tipo espec√≠fico de variable aleatoria discreta que s√≥lo toma dos posibles valores, t√≠picamente 0 y 1, para representar los resultados de un √∫nico ensayo de Bernoulli**. Este tipo de variable es fundamental en probabilidad y estad√≠stica para modelar el resultado de experimentos que tienen exactamente dos posibles resultados, com√∫nmente etiquetados como "√©xito" y "fracaso".

### Definici√≥n

Una variable de Bernoulli $$X$$ se define de la siguiente manera:
- $$X = 1$$ con probabilidad $$p$$ (√©xito).
- $$X = 0$$ con probabilidad $$1-p$$ (fracaso).


### Ejemplo con la Suma de Dos Dados

Si consideramos la variable $$S$$ como la suma de dos lanzamientos de un dado:
- $$P(S = 2) = \frac{1}{36}$$ porque solo hay una forma de obtener un 2: lanzando dos unos.
- $$P(S = 3) = \frac{2}{36}$$ porque hay dos combinaciones que dan un 3: (1,2) y (2,1).
- Y as√≠ sucesivamente hasta $$S = 12$$.

Estos c√°lculos asumen que todos los resultados son igualmente probables, lo cual es cierto para un dado justo.

### Aplicaci√≥n Pr√°ctica: Variable Aleatoria Bernoulli

{: .highlight}
Una **variable aleatoria Bernoulli** es un tipo especial de variable aleatoria discreta que solo toma dos valores, generalmente 0 y 1. Es extremadamente √∫til para modelar experimentos binarios como el lanzamiento de una moneda.

#### Ejemplo con el Lanzamiento de una Moneda
- Si la moneda es justa, $$P(X = 1) = 0.5$$ y $$P(X = 0) = 0.5$$.
- Si la moneda no es justa y la probabilidad de cara es 0.7, entonces $$P(X = 1) = 0.7$$ y $$P(X = 0) = 0.3$$.

La **PMF** en este caso asignar√≠a 0.7 a obtener cara y 0.3 a obtener cruz, reflejando la naturaleza sesgada de la moneda.

### Simulaci√≥n en Python

Vamos a construir una funci√≥n en Python que simule un experimento de Bernoulli, el cual podr√≠a representar, por ejemplo, el lanzamiento de una moneda:

```python
import numpy as np

def bernoulli_trial(p=0.5):
    """Simula un experimento de Bernoulli.
        Args:
    p (float): Probabilidad de √©xito (por defecto 0.5).
        Returns:
    int: 1 si el experimento resulta en √©xito, 0 en caso contrario.
    """
    return 1 if np.random.rand() <= p else 0
```

En esta funci√≥n, `np.random.rand()` genera un n√∫mero aleatorio entre 0 y 1, y compara este n√∫mero con la probabilidad de √©xito `p`. Si el n√∫mero generado es menor o igual a `p`, el resultado es un √©xito (1); de lo contrario, es un fracaso (0).

### Simulaci√≥n y An√°lisis de Resultados

Podemos usar esta funci√≥n para realizar m√∫ltiples ensayos y observar la frecuencia de √©xitos, lo que nos permite estimar la probabilidad de √©xito de la moneda:

```python
def simulate_bernoulli_trials(n, p=0.5):
    """Simula n ensayos de Bernoulli y reporta la frecuencia de √©xitos.
        Args:
    n (int): N√∫mero de ensayos.
    p (float): Probabilidad de √©xito.
    
    Returns:
    float: Frecuencia de √©xitos.
    """
    results = [bernoulli_trial(p) for _ in range(n)]
    return sum(results) / n

# Simular 1000 lanzamientos de una moneda con p = 0.7
n_trials = 1000
success_prob = 0.612199
frequency_of_success = simulate_bernoulli_trials(n_trials, success_prob)

print(f"La frecuencia de √©xito estimada es {frequency_of_success:.2f}")
```
Output:
```
La frecuencia de √©xito estimada es 0.71
```

Este c√≥digo simula 1000 lanzamientos de una moneda donde la probabilidad de obtener cara (√©xito) es del 70%. La funci√≥n simulate_bernoulli_trials devuelve la frecuencia de √©xitos, que deber√≠a acercarse a 0.7 a medida que el n√∫mero de ensayos aumenta.

### Visualizaci√≥n de la Convergencia

Para visualizar c√≥mo la frecuencia de √©xitos converge a la probabilidad real, podr√≠amos realizar m√∫ltiples simulaciones aumentando progresivamente el n√∫mero de ensayos y graficar los resultados:

```python
import matplotlib.pyplot as plt

trial_counts = [10, 50, 100, 500, 1000, 5000, 10000]
frequencies = [simulate_bernoulli_trials(count, success_prob) for count in trial_counts]

plt.figure(figsize=(10, 5))
plt.plot(trial_counts, frequencies, marker='o', linestyle='-')
plt.axhline(y=success_prob, color='r', linestyle='--')
plt.title('Convergencia de la Frecuencia de √âxitos a la Probabilidad Real')
plt.xlabel('N√∫mero de Ensayos')
plt.ylabel('Frecuencia de √âxitos')
plt.xscale('log')
plt.show()
```

![Visualizaci√≥n de la Convergencia](https://fer78docs.github.io/assets/images/Visualizaci√≥n de la Convergencia.png)

Este gr√°fico mostrar√° c√≥mo la frecuencia de √©xitos se estabiliza y converge hacia la probabilidad real de √©xito (0.612199 en este caso) a medida que aumenta el n√∫mero de ensayos, ilustrando la ley de los grandes n√∫meros.

### Funci√≥n de Masa de Probabilidad (PMF)  

{: .highlight}
La Funci√≥n de Masa de Probabilidad (PMF) es una funci√≥n que **describe la probabilidad de que una variable aleatoria discreta tome un valor espec√≠fico**. Es una funci√≥n que devuelve la probabilidad de que una variable aleatoria discreta sea exactamente igual a alg√∫n valor.‚Äã Es una funci√≥n que asocia a cada punto de su espacio muestral X la probabilidad de que esta lo asuma. La funci√≥n de probabilidad suele ser el medio principal para definir una distribuci√≥n de probabilidad discreta, y tales funciones existen para variables aleatorias escalares o multivariantes, cuyo dominio es discreto.

La funci√≥n de masa de probabilidad de un dado. Todos los n√∫meros tienen la misma probabilidad de aparecer cuando este es tirado.
![pmf_dado](https://fer78docs.github.io/assets/images/funcion_de_masa_probabilidad.png)

### Tipos de Variables Aleatorias Discretas

Los tipos de variables aleatorias discretas se clasifican com√∫nmente seg√∫n las distribuciones de probabilidad que describen c√≥mo se comportan los datos asociados a estas variables. Aqu√≠ describo algunas de las distribuciones m√°s comunes y utilizadas para variables aleatorias discretas.
En Python, la librer√≠a `scipy.stats` proporciona implementaciones de las PMFs para muchas distribuciones discretas comunes, lo que facilita su c√°lculo en la pr√°ctica. Estas funciones son extremadamente √∫tiles para simulaciones, modelado estad√≠stico y an√°lisis probabil√≠stico en una amplia gama de aplicaciones.

1. **Distribuci√≥n Binomial**:  
   Usada cuando se est√°n observando el n√∫mero de √©xitos en un n√∫mero fijo de ensayos independientes y cada ensayo tiene solo dos posibles resultados (√©xito o fracaso).  
   La PMF de una distribuci√≥n binomial describe la probabilidad de obtener un n√∫mero espec√≠fico de √©xitos en un n√∫mero fijo de ensayos independientes, cada uno con dos posibles resultados y una misma probabilidad de √©xito.

    ```python
    from scipy.stats import binom
    import numpy

    # Par√°metros
    n = 10  # n√∫mero de ensayos
    p = 0.5  # probabilidad de √©xito
    size = 100 # muestras a generar

    # Generar Variables
    numpy.random.binomial(n, p, size)

    # Calcular PMF para un valor espec√≠fico
    k = 5  # n√∫mero de √©xitos
    prob = binom.pmf(k, n, p)
    print(f"Probabilidad de {k} √©xitos en {n} ensayos: {prob:.4f}")
    ```


2. **Distribuci√≥n de Poisson**:
    Aplica para modelar el n√∫mero de eventos en un intervalo de tiempo o espacio fijo cuando estos eventos ocurren con una tasa media conocida y de manera independiente entre s√≠.
    La PMF de una distribuci√≥n de Poisson mide la probabilidad de un n√∫mero determinado de eventos ocurriendo en un intervalo fijo, dado que estos eventos ocurren con una tasa media conocida y de manera independiente.

    ```python
    from scipy.stats import poisson
    import numpy

    lambda_ = 3  # tasa media de eventos por intervalo
    zize = 10 # n√∫mero de muestras a generar.

    # Generar variables
    numpy.random.poisson(lambda_, size)

    # Calcular PMF
    k = 4  # n√∫mero de eventos
    prob = poisson.pmf(k, lambda_)
    print(f"Probabilidad de {k} eventos: {prob:.4f}")
    ```


3. **Distribuci√≥n Geom√©trica**:
    Describe el n√∫mero de ensayos necesarios para obtener el primer √©xito en una secuencia de ensayos independientes, cada uno con dos posibles resultados.
    La PMF de una distribuci√≥n geom√©trica describe la probabilidad de que el primer √©xito ocurra en el ensayo $$ùëò$$

    ```python
    from scipy.stats import geom
    import numpy
    
    p = 0.2  # probabilidad de √©xito en cada ensayo
    zize = 10 # n√∫mero de muestras a generar.

    # generar variable
    numpy.random.geometric(p, size)

    # Calcular PMF
    k = 5  # ensayo en el que ocurre el primer √©xito
    prob = geom.pmf(k, p)
    print(f"Probabilidad de primer √©xito en el intento {k}: {prob:.4f}")
    ```

4. **Distribuci√≥n Binomial Negativa**:
    Generaliza la distribuci√≥n geom√©trica para contar el n√∫mero de ensayos requeridos para obtener un n√∫mero fijo de √©xitos.
    Esta distribuci√≥n cuenta cu√°ntos ensayos son necesarios para lograr un n√∫mero especificado de √©xitos.

    ```python
    from scipy.stats import nbinom
    import numpy

    r = 5  # n√∫mero de √©xitos deseados
    p = 0.5  # probabilidad de √©xito en cada ensayo
    zize = 10 # n√∫mero de muestras a generar.

    # generar variable
    numpy.random.negative_binomial(n, p, size)

    # Calcular PMF
    k = 10  # total de ensayos
    prob = nbinom.pmf(k-r, r, p)
    print(f"Probabilidad de alcanzar {r} √©xitos en {k} ensayos: {prob:.4f}")
    ```

5. **Distribuci√≥n Hipergeom√©trica**:
    Modela el n√∫mero de √©xitos en una muestra de tama√±o fijo tomada sin reemplazo de una poblaci√≥n que consta de dos tipos de objetos (√©xitos y fracasos).  
    La PMF de la distribuci√≥n hipergeom√©trica describe la probabilidad de obtener un n√∫mero determinado de √©xitos en una muestra extra√≠da sin reemplazo de una poblaci√≥n finita que consta de dos tipos de objetos.

    ```python
    from scipy.stats import hypergeom
    import numpy
    
    M = 20  # tama√±o total de la poblaci√≥n
    n = 7   # n√∫mero de √©xitos en la poblaci√≥n
    N = 12  # tama√±o de la muestra

    # Calcular PMF
    k = 3  # n√∫mero de √©xitos observados en la muestra
    prob = hypergeom.pmf(k, M, n, N)
    print(f"Probabilidad de {k} √©xitos en una muestra de {N}: {prob:.4f}")

    # generar variable
    ngood   # n√∫mero de elementos "buenos" en la poblaci√≥n.
    nbad    # n√∫mero de elementos "malos" en la poblaci√≥n.
    nsample # n√∫mero de elementos a muestrear (sin reemplazo).
    size    # n√∫mero de muestras a generar.

    numpy.random.hypergeometric(ngood, nbad, nsample, size=None)
   ```

6. **Distribuci√≥n Uniforme Discreta**:
   - Todos los valores posibles de la variable tienen la misma probabilidad de ocurrir.
   - Par√°metros: el m√≠nimo y m√°ximo valor que puede tomar la variable.

7. **Distribuci√≥n de Bernoulli**:
   - Un caso especial de la distribuci√≥n binomial con un solo ensayo $$n = 1$$.
   - Par√°metro: probabilidad de √©xito $$p$$.

8. **Distribuci√≥n Multinomial**:
   - Extensi√≥n de la distribuci√≥n binomial para situaciones en las que cada ensayo puede resultar en m√°s de dos categor√≠as.
   - Par√°metros: n√∫mero de ensayos $$n$$ y vector de probabilidades $$p$$ para cada categor√≠a.

Estas distribuciones permiten modelar una gran variedad de procesos y fen√≥menos en diversos campos como la biolog√≠a, ingenier√≠a, econom√≠a, ciencias sociales, y m√°s. Cada tipo de distribuci√≥n proporciona un modelo estad√≠stico que se adapta a las caracter√≠sticas espec√≠ficas de los datos y la naturaleza del experimento o la observaci√≥n realizada.


## Variables aleatorias continuas

{: .note}
Las **variables aleatorias continuas** son aquellas que pueden tomar cualquier valor num√©rico dentro de un intervalo o conjunto de intervalos, a diferencia de las variables aleatorias discretas que tienen valores contables y separados. Este tipo de variables es fundamental en estad√≠stica y probabilidad para modelar fen√≥menos que requieren una escala de medida infinita y continua.

### Caracter√≠sticas Principales

1. **Valores no Contables**: Las variables aleatorias continuas pueden adoptar cualquier valor dentro de un rango espec√≠fico, que puede ser finito o infinito.
2. **Funci√≥n de Densidad de Probabilidad (PDF)**: A diferencia de las variables discretas que usan una funci√≥n de probabilidad de masa, las continuas se describen mediante una funci√≥n de densidad de probabilidad. Esta funci√≥n no proporciona probabilidades directamente, sino que el √°rea bajo la curva de la funci√≥n entre dos puntos corresponde a la probabilidad de que la variable aleatoria caiga dentro de ese intervalo.

### Ejemplos de Variables Aleatorias Continuas

- **Altura de los estudiantes en una clase**: La altura puede variar continuamente y puede ser cualquier valor dentro de un rango razonable, por ejemplo, entre 1.50 metros y 2.00 metros.
- **Tiempo necesario para completar una tarea**: Este tiempo puede ser cualquier n√∫mero no negativo, medido con precisi√≥n hasta fracciones de segundo.
- **Presi√≥n en un tanque de gas**: La presi√≥n puede fluctuar y tomar cualquier valor dentro de los l√≠mites de seguridad del tanque.

### Distribuciones Comunes de Variables Aleatorias Continuas

- **Distribuci√≥n Normal (Gaussiana)**: Una de las distribuciones m√°s importantes y comunes en estad√≠stica. Es sim√©trica y describe fen√≥menos naturales, sociales y de medici√≥n donde los valores tienden a agruparse alrededor de un promedio.
- **Distribuci√≥n Exponencial**: Usada para modelar el tiempo entre eventos en un proceso de Poisson, como el tiempo entre llamadas telef√≥nicas en un call center.
- **Distribuci√≥n Uniforme**: Describe una situaci√≥n donde todos los valores dentro de un cierto intervalo son igualmente probables, como elegir un n√∫mero al azar entre 0 y 1.




### Variables Aleatorias Continuas

1. **Normal (Gaussiana)**:

   - `loc`: media de la distribuci√≥n (mu).
   - `scale`: desviaci√≥n est√°ndar de la distribuci√≥n (sigma).
   - `size`: n√∫mero de muestras a generar.

   ```python
   numpy.random.normal(loc=0.0, scale=1.0, size=None)
   ```
   Genera n√∫meros a partir de una distribuci√≥n normal con media `loc` y desviaci√≥n est√°ndar `scale`.

2. **Exponencial**:

   - `scale`: inverso de la tasa (lambda), a veces llamado par√°metro de escala.
   - `size`: n√∫mero de muestras a generar.

   ```python
   numpy.random.exponential(scale=1.0, size=None)
   ```
   Genera n√∫meros a partir de una distribuci√≥n exponencial con un par√°metro de escala.

3. **Uniforme**:

   - `low`: l√≠mite inferior del rango de los valores.
   - `high`: l√≠mite superior del rango de los valores.
   - `size`: n√∫mero de muestras a generar.

   ```python
   numpy.random.uniform(low=0.0, high=1.0, size=None)
   ```
   Genera n√∫meros a partir de una distribuci√≥n uniforme entre `low` y `high`.

4. **Beta**:

   - `a`: par√°metro de forma alpha.
   - `b`: par√°metro de forma beta.
   - `size`: n√∫mero de muestras a generar.

   ```python
   numpy.random.beta(a, b, size=None)
   ```
   Genera n√∫meros a partir de una distribuci√≥n beta con par√°metros `a` y `b`.

5. **Gamma**:

   - `shape`: par√°metro de forma (k).
   - `scale`: par√°metro de escala (theta).
   - `size`: n√∫mero de muestras a generar.

   ```python
   numpy.random.gamma(shape, scale=1.0, size=None)
   ```
   Genera n√∫meros a partir de una distribuci√≥n gamma con un par√°metro de forma y escala.

Estos m√©todos permiten simular datos que siguen estas distribuciones, lo que es √∫til en simulaciones, pruebas de hip√≥tesis, y para entender mejor el comportamiento estad√≠stico de fen√≥menos modelados por estas distribuciones.